Data Discription:
  File: features.csv
  Columns: ['Store', 'Date', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday']
  
  File: stores.csv
  Columns: ['Store', 'Type', 'Size']
  
  File: test.csv
  Columns: ['Store', 'Dept', 'Date', 'IsHoliday']
  
  File: train.csv
  Columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday']


 **ğŸš€ ETL Pipeline: Walmart Sales Data Analysis Using PySpark**  

ğŸ”¹ **Dataset Overview**  
I worked with **Walmart Sales Data**, consisting of the following files:  

ğŸ“‚ **`features.csv`** â€“ Storespecific details:  
`['Store', 'Date', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday']`  

ğŸ“‚ **`stores.csv`** â€“ Store information:  
`['Store', 'Type', 'Size']`  

ğŸ“‚ **`train.csv`** â€“ Weekly sales data:  
`['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday']`  



 **ğŸ› ï¸ ETL Process Breakdown**  

1ï¸âƒ£ **Data Type Correction** â€“ Despite using `inferSchema=True`, some data types were incorrectly inferred. Explicit type casting was applied.  

2ï¸âƒ£ **Handling Missing Values** â€“ Checked **Markdown15** columns for `null` values.  

3ï¸âƒ£ **Imputation** â€“ Replaced missing values in **Markdown15** with their respective mean values.  

4ï¸âƒ£ **Date Format Validation** â€“ Ensured the **Date** column follows the `"yyyyMMdd"` format. No changes were needed.  

5ï¸âƒ£ **Feature Engineering** â€“ Calculated a **4Week Moving Average** for `Weekly_Sales` to identify trends.  

6ï¸âƒ£ **StoreWise Sales Analysis** â€“ Aggregated key metrics per store:  
   âœ… `Total_Weekly_Sales`  
   âœ… `Avg_Weekly_Sales`  
   âœ… `Max_Weekly_Sales`  
   âœ… `Min_Weekly_Sales`  
   âœ… `Total_Transactions`  
   
7ï¸âƒ£ **Merging Datasets** â€“ Combined `stores.csv` with aggregated store performance data for better analytics.  

8ï¸âƒ£ **Final Data Exports** â€“ Saved the transformed datasets for further **BI Reporting & Visualization**:  
   ğŸ“Œ `joined_data.csv` â€“ Merged dataset for sales analysis.  
   ğŸ“Œ `store_wise_stats.csv` â€“ Storelevel aggregated insights.  



 **ğŸ” Output Files & Schema**  

ğŸ“„ **`joined_data.csv`**:  
`['Store', 'Date', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday', 'Dept', 'Weekly_Sales', 'IsHoliday', '4_Week_Moving_Avg']`  

ğŸ“„ **`store_wise_stats.csv`**:  
`['Store', 'Total_Weekly_Sales', 'Avg_Weekly_Sales', 'Max_Weekly_Sales', 'Min_Weekly_Sales', 'Total_Transactions', 'Type', 'Size']`  



ğŸ”¥ **Next Steps:** Visualizing these insights using **Tableau or Power BI** to identify key business trends.  

ğŸš€ Looking for Data Engineering Opportunities!
I am a passionate fresher eager to start my journey in Data Engineering. This project helped me gain hands-on experience in ETL processes, PySpark, and Data Analytics. I am actively looking for opportunities where I can apply my skills, learn, and contribute to impactful projects.

If you're hiring or have any guidance, I would love to connect and discuss potential roles! Feel free to reach out or share any advice in the comments. Letâ€™s build something amazing together! ğŸ’¡ğŸ’¼
